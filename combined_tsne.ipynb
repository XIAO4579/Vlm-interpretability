{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import eval_model\n",
    "\n",
    "###\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"\"\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path=model_path,\n",
    "    model_base=None,\n",
    "    model_name=get_model_name_from_path(model_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the flower is yellow. tensor([[    1,   450,  2927,   310,   278, 28149,   338, 13328, 29889,     2]],\n",
      "       device='cuda:0')\n",
      "The color of the flower is pink. tensor([[    1,   450,  2927,   310,   278, 28149,   338,   282,   682, 29889,\n",
      "             2]], device='cuda:0')\n",
      "The color of the flower is white. tensor([[    1,   450,  2927,   310,   278, 28149,   338,  4796, 29889,     2]],\n",
      "       device='cuda:0')\n",
      "The color of the flower is red. tensor([[    1,   450,  2927,   310,   278, 28149,   338,  2654, 29889,     2]],\n",
      "       device='cuda:0')\n",
      "The color of the flower is purple. tensor([[    1,   450,  2927,   310,   278, 28149,   338,  3708,   552, 29889,\n",
      "             2]], device='cuda:0')\n",
      "The color of the flower is white. tensor([[    1,   450,  2927,   310,   278, 28149,   338,  4796, 29889,     2]],\n",
      "       device='cuda:0')\n",
      "The color of the flower is pink. tensor([[    1,   450,  2927,   310,   278, 28149,   338,   282,   682, 29889,\n",
      "             2]], device='cuda:0')\n",
      "The color of the flower is purple. tensor([[    1,   450,  2927,   310,   278, 28149,   338,  3708,   552, 29889,\n",
      "             2]], device='cuda:0')\n",
      "The color of the flower is red. tensor([[    1,   450,  2927,   310,   278, 28149,   338,  2654, 29889,     2]],\n",
      "       device='cuda:0')\n",
      "The color of the flower is pink. tensor([[    1,   450,  2927,   310,   278, 28149,   338,   282,   682, 29889,\n",
      "             2]], device='cuda:0')\n",
      "The color of the flower is red. tensor([[    1,   450,  2927,   310,   278, 28149,   338,  2654, 29889,     2]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "# List to store hidden states corresponding to the token of interest for each image.\n",
    "token_hidden_states = []\n",
    "num_images = 12  # Total number of images to process\n",
    "\n",
    "# Loop over each image.\n",
    "for i in range(num_images):\n",
    "    image_file = f\"./image/flower/flower{i+1}.jpg\"\n",
    "    prompt = 'What is the color of the flower?'  # Prompt can be adjusted as needed  ##\"What is the color of the flower? The color of the flower is\" \n",
    "    args = type('Args', (), {\n",
    "        \"model_base\": None,\n",
    "        \"model_name\": get_model_name_from_path(model_path),\n",
    "        \"query\": prompt,\n",
    "        \"conv_mode\": None,\n",
    "        \"image_file\": image_file,\n",
    "        \"sep\": \",\",\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": None,\n",
    "        \"num_beams\": 1,\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"model\": model,\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"image_processor\": image_processor,\n",
    "        \"output_hidden_states\": True,\n",
    "        \"return_dict_in_generate\": True,\n",
    "    })()\n",
    "\n",
    "    all_output = eval_model(args)\n",
    "    output_text = tokenizer.decode(all_output['sequences'][0], skip_special_tokens=True)\n",
    "    \n",
    "    # Print the model output for debugging\n",
    "    print(output_text, all_output['sequences'])\n",
    "    \n",
    "    # Define the token position to analyze (e.g., token \"color\" is at index 6).\n",
    "    location = 6\n",
    "    hidden_states = all_output[\"hidden_states\"]\n",
    "    dataset = []\n",
    "    \n",
    "    # Loop over time steps for the specified token location.\n",
    "    # If location == 0, use the last token's hidden state; otherwise, use the full hidden state.\n",
    "    for t in range(len(hidden_states[0])):\n",
    "        if location == 0:\n",
    "            state = hidden_states[location][t][:, -1, :]\n",
    "            dataset.append(np.squeeze(state.cpu().numpy()))\n",
    "        else:\n",
    "            dataset.append(np.squeeze(hidden_states[location][t].cpu().numpy()))\n",
    "    \n",
    "    # Remove the first token (usually a special token like </s>) and store the hidden states.\n",
    "    token_hidden_states.append(np.array(dataset)[1:, :])\n",
    "\n",
    "# Stack the hidden states from all images vertically.\n",
    "data_array = np.vstack(token_hidden_states)\n",
    "\n",
    "# Normalize the data using MaxAbsScaler.\n",
    "scaler = MaxAbsScaler()\n",
    "data_flat_scaled = scaler.fit_transform(data_array)\n",
    "\n",
    "def generate_colors(cmap_name, num_colors):\n",
    "    \"\"\"\n",
    "    Generate a list of hex color codes from a specified Matplotlib colormap.\n",
    "\n",
    "    Args:\n",
    "        cmap_name (str): Name of the colormap (e.g., 'Blues_r').\n",
    "        num_colors (int): Number of colors to generate.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of hex color codes.\n",
    "    \"\"\"\n",
    "    cmap = plt.get_cmap(cmap_name, num_colors)\n",
    "    return [to_hex(cmap(i)) for i in range(num_colors)]\n",
    "\n",
    "# Define labels for each group of layers.\n",
    "# For the 7b model, labels correspond to:\n",
    "# 0 -> first 2 layers, 1 -> layers 3 to 19, 2 -> layers 20 to 31, 3 -> 32nd layer.\n",
    "labels_per_array = np.concatenate([\n",
    "    np.repeat(0, 2),\n",
    "    np.repeat(1, 17),\n",
    "    np.repeat(2, 12),\n",
    "    np.repeat(3, 1),\n",
    "])\n",
    "# For a 13b model, use these labels instead:\n",
    "# labels_per_array = np.concatenate([\n",
    "#     np.repeat(0, 2),\n",
    "#     np.repeat(1, 17),\n",
    "#     np.repeat(2, 20),\n",
    "#     np.repeat(3, 1),\n",
    "# ])\n",
    "\n",
    "# Repeat the label array for each image.\n",
    "labels_flat = np.tile(labels_per_array, num_images)\n",
    "\n",
    "# Ensure the total number of labels matches the number of data samples.\n",
    "assert len(labels_flat) == data_flat_scaled.shape[0], \"Mismatch between labels and data samples.\"\n",
    "\n",
    "# Apply t-SNE for dimensionality reduction to 2D.\n",
    "tsne = TSNE(n_components=2, perplexity=35, learning_rate=200, n_iter=2000, random_state=0)\n",
    "data_tsne = tsne.fit_transform(data_flat_scaled)\n",
    "\n",
    "# Define names for each label group.\n",
    "label_names = [\n",
    "    'the first two layers',\n",
    "    '3rd layer to 18th layer',\n",
    "    '19th layer to 31st layer',\n",
    "    '32nd layer'\n",
    "]\n",
    "\n",
    "# Define a set of colors for plotting.\n",
    "colors = ['#FF6347', '#3CB371', '#4682B4', '#9370DB', \n",
    "          '#FFA07A', '#FFDAB9', '#87CEFA', '#FFB6C1']\n",
    "\n",
    "# Create a t-SNE scatter plot.\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, label in enumerate(np.unique(labels_flat)):\n",
    "    idx = labels_flat == label\n",
    "    plt.scatter(\n",
    "        data_tsne[idx, 0],\n",
    "        data_tsne[idx, 1],\n",
    "        color=colors[i],\n",
    "        label=label_names[i],\n",
    "        s=25,\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "# Remove axis ticks and labels for a cleaner look.\n",
    "plt.tick_params(\n",
    "    axis='both',\n",
    "    which='both',\n",
    "    bottom=False,\n",
    "    top=False,\n",
    "    labelbottom=False,\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelleft=False\n",
    ")\n",
    "\n",
    "# Customize the plot spines (borders).\n",
    "ax = plt.gca()\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_color('dimgray')\n",
    "    spine.set_linewidth(0.8)\n",
    "\n",
    "# Add legend and grid.\n",
    "plt.legend(loc='upper right', prop={'size': 20, 'weight': 'bold'})\n",
    "plt.grid(True, linestyle='--', alpha=0.5, zorder=0.1)\n",
    "\n",
    "# Save and display the plot.\n",
    "# plt.savefig('color_combine_animal.png', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
